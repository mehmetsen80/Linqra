networks:
  linqra-network:
    external: true
    driver_opts:
      com.docker.network.driver.mtu: 1500

services:
  # postgres
  postgres-service:
    build:
      context: .
      dockerfile: ./.kube/postgres/Dockerfile
    container_name: postgres-service
    command: postgres -c "max_connections=200"
    restart: always
    ports:
      - "5432:5432"
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB" ]
      interval: 10s
      timeout: 3s
      retries: 3
    volumes:
      - ./.kube/postgres/data/:/var/lib/postgresql/pgdata
      - ./secrets:/app/secrets:ro
    environment:
      VAULT_MASTER_KEY: ${VAULT_MASTER_KEY}
      VAULT_ENVIRONMENT: ${VAULT_ENVIRONMENT:-ec2}
      VAULT_REQUIRED_VARS: POSTGRES_DB,POSTGRES_USER,POSTGRES_PASSWORD
    networks:
      - linqra-network

  # postgres admin
  pgadmin-service:
    build:
      context: .
      dockerfile: ./.kube/pgadmin/Dockerfile
    restart: always
    ports:
      - "9090:80"
    environment:
      PGADMIN_DEFAULT_EMAIL: user-name@domain-name.com
      PGADMIN_DEFAULT_PASSWORD: strong-password
    volumes:
      - ./.kube/pgadmin/data/:/var/lib/pgadmin
    networks:
      - linqra-network

  # keycloak
  keycloak-service:
    build:
      context: .
      dockerfile: ./.kube/keycloak/Dockerfile
    environment:
      KC_DB: postgres
      KC_HTTP_ENABLED: true
      KC_HTTP_PORT: 8080
      KC_HTTP_RELATIVE_PATH: /keycloak

      KC_HOSTNAME: https://linqra.com
      KC_HOSTNAME_STRICT: true
      KC_HOSTNAME_STRICT_HTTPS: true
      KC_HOSTNAME_ADMIN: https://linqra.com/keycloak
      KC_HOSTNAME_URL: https://linqra.com/keycloak
      KC_FRONTEND_URL: https://linqra.com/keycloak

      KC_PROXY: edge
      PROXY_ADDRESS_FORWARDING: true

      KC_LOG_LEVEL: info
      KC_METRICS_ENABLED: true
      KC_HEALTH_ENABLED: true
      KC_FEATURES: admin

      KC_SPI_RESOURCES_PUBLIC_URL: https://linqra.com/keycloak/resources
      KC_SPI_LOGIN_PROTOCOL_OPENID_CONNECT_REDIRECT_HOSTNAME: https://linqra.com/keycloak
      KC_SPI_LOGIN_PROTOCOL_OPENID_CONNECT_LEGACY_IFRAME_COMPATIBLE: "true"
      KC_SPI_LOGIN_PROTOCOL_OPENID_CONNECT_SUPPRESS_LOGOUT_CONFIRMATION_SCREEN: "true"
      VAULT_MASTER_KEY: ${VAULT_MASTER_KEY}
      VAULT_ENVIRONMENT: ${VAULT_ENVIRONMENT:-ec2}
      VAULT_REQUIRED_VARS: POSTGRES_DB,POSTGRES_USER,POSTGRES_PASSWORD,KEYCLOAK_ADMIN,KEYCLOAK_ADMIN_PASSWORD

    command:
      - start
    volumes:
      - ./.kube/keycloak/data/import:/opt/keycloak/data/import
      - ./.kube/keycloak/data/export:/opt/keycloak/data/export
      - ./.kube/keycloak/themes:/opt/keycloak/themes
      - ./secrets:/app/secrets:ro
    depends_on:
      postgres-service:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "-H", "Host: localhost", "http://localhost:8080/health/ready" ]
      interval: 10s
      timeout: 3s
      retries: 3
    ports:
      - "8281:8080"
    networks:
      - linqra-network

  # etcd for Milvus
  # etcd-service:
  #   image: quay.io/coreos/etcd:v3.5.5
  #   environment:
  #     - ETCD_AUTO_COMPACTION_MODE=revision
  #     - ETCD_AUTO_COMPACTION_RETENTION=1000
  #     - ETCD_QUOTA_BACKEND_BYTES=4294967296
  #     - ETCD_SNAPSHOT_COUNT=50000
  #   volumes:
  #     - ./.kube/etcd/data:/etcd
  #   command: etcd -advertise-client-urls=http://etcd-service:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd
  #   healthcheck:
  #     test: [ "CMD", "etcdctl", "endpoint", "health" ]
  #     interval: 10s
  #     timeout: 3s
  #     retries: 3
  #   networks:
  #     - linqra-network

  # MinIO for Milvus
  # minio-service:
  #   build:
  #     context: .
  #     dockerfile: ./.kube/minio/Dockerfile
  #   environment:
  #     VAULT_MASTER_KEY: ${VAULT_MASTER_KEY}
  #     VAULT_ENVIRONMENT: ${VAULT_ENVIRONMENT:-ec2}
  #     VAULT_REQUIRED_VARS: MINIO_ACCESS_KEY,MINIO_SECRET_KEY
  #   volumes:
  #     - ./.kube/minio/data:/data
  #     - ./secrets:/app/secrets:ro
  #   command: [ "server", "/data", "--console-address", ":9001" ]
  #   healthcheck:
  #     test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
  #     interval: 10s
  #     timeout: 3s
  #     retries: 3
  #   networks:
  #     - linqra-network

  # Milvus vector database
  # milvus-service:
  #   build:
  #     context: .
  #     dockerfile: ./.kube/milvus/Dockerfile
  #   container_name: milvus-service
  #   environment:
  #     ETCD_ENDPOINTS: etcd-service:2379
  #     MINIO_ADDRESS: minio-service:9000
  #     COMMON_CFG_RETENTION_DURATION: 168h
  #     COMMON_SECURITY_AUTHORIZATIONENABLED: "true"
  #     VAULT_MASTER_KEY: ${VAULT_MASTER_KEY}
  #     VAULT_ENVIRONMENT: ${VAULT_ENVIRONMENT:-ec2}
  #     VAULT_REQUIRED_VARS: MILVUS_USERNAME,MILVUS_PASSWORD,MINIO_ACCESS_KEY,MINIO_SECRET_KEY
  #   volumes:
  #     - ./.kube/milvus/data:/var/lib/milvus
  #     - ./secrets:/app/secrets:ro
  #   ports:
  #     - "19530:19530"
  #     - "9091:9091"
  #   networks:
  #     - linqra-network
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '2.0'
  #         memory: 4G
  #     restart_policy:
  #       condition: on-failure
  #   depends_on:
  #     - etcd-service
  #     - minio-service
  #   healthcheck:
  #     test: [ "CMD", "curl", "-f", "http://localhost:9091/api/v1/health" ]
  #     interval: 10s
  #     timeout: 3s
  #     retries: 3

  # Attu UI for Milvus
  # attu-service:
  #   build:
  #     context: .
  #     dockerfile: ./.kube/attu/Dockerfile
  #   environment:
  #     MILVUS_URL: milvus-service:19530
  #     MILVUS_DATABASE: default
  #     MILVUS_USE_SSL: "false"
  #   ports:
  #     - "8000:3000"
  #   networks:
  #     - linqra-network
  #   depends_on:
  #     - milvus-service

  # Neo4j Graph Database
  # Neo4j Graph Database
  # neo4j-service:
  #   build:
  #     context: .
  #     dockerfile: ./.kube/neo4j/Dockerfile
  #   container_name: neo4j-service
  #   environment:
  #     - NEO4J_PLUGINS=["apoc"]
  #     - NEO4J_dbms_memory_heap_initial__size=256m
  #     - NEO4J_dbms_memory_heap_max__size=512m
  #     - NEO4J_dbms_memory_pagecache_size=512m
  #     - NEO4J_dbms_connector_bolt_listen__address=0.0.0.0:7687
  #     - NEO4J_dbms_connector_http_listen__address=0.0.0.0:7474
  #     - NEO4J_dbms_security_procedures_unrestricted=apoc.*
  #     - NEO4J_dbms_security_procedures_allowlist=apoc.*
  #     - VAULT_MASTER_KEY=${VAULT_MASTER_KEY}
  #     - VAULT_ENVIRONMENT=${VAULT_ENVIRONMENT:-ec2}
  #     - VAULT_REQUIRED_VARS=NEO4J_USERNAME,NEO4J_PASSWORD
  #   ports:
  #     - "7474:7474" # HTTP
  #     - "7687:7687" # Bolt (Java driver uses this)
  #   volumes:
  #     - ./.kube/neo4j/data:/data
  #     - ./.kube/neo4j/logs:/logs
  #     - ./.kube/neo4j/import:/var/lib/neo4j/import
  #     - ./.kube/neo4j/plugins:/plugins
  #     - ./secrets:/app/secrets:ro
  #   healthcheck:
  #     test: [ "CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:7474/" ]
  #     interval: 10s
  #     timeout: 3s
  #     retries: 3
  #   networks:
  #     - linqra-network
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '1.0'
  #         memory: 1.5G
  #       reservations:
  #         cpus: '0.5'
  #         memory: 512M
  #     restart_policy:
  #       condition: on-failure

  # Discovery Server (Eureka)
  discovery-service:
    build:
      context: .
      dockerfile: .kube/eureka/Dockerfile
    environment:
      VAULT_ENVIRONMENT: ${VAULT_ENVIRONMENT:-ec2}
      VAULT_MASTER_KEY: ${VAULT_MASTER_KEY}
    ports:
      - "8761:8761"
    volumes:
      - ./discovery-server:/app/discovery-server
      - ./keys:/app/keys
      - ./secrets:/app/secrets:ro
    networks:
      - linqra-network

  # Load Balancer
  gateway-loadbalancer:
    image: haproxy:2.8
    ports:
      - "7777:7777"
    volumes:
      - ./.kube/gateway/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
      - ./keys/haproxy/gateway-combined-container.pem:/etc/ssl/gateway-cert.pem:ro
    networks:
      - linqra-network
    depends_on:
      - api-gateway-service

  # API Gateway Service
  api-gateway-service:
    build:
      context: .
      dockerfile: ./.kube/gateway/Dockerfile
    environment:
      VAULT_ENVIRONMENT: ${VAULT_ENVIRONMENT:-ec2}
      VAULT_MASTER_KEY: ${VAULT_MASTER_KEY}
      VAULT_REQUIRED_VARS: SPRING_PROFILES_ACTIVE,AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY,GATEWAY_TRUSTSTORE_PASSWORD
    volumes:
      - ./keys:/app/keys
      - ./secrets:/app/secrets:ro
      # Mount data directories for backup scheduler access (read-write for backups)
      - ./.kube:/var/www/linqra/.kube
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G
      replicas: 1
      restart_policy:
        condition: on-failure
    expose:
      - "7777"
    networks:
      - linqra-network
    depends_on:
      - discovery-service
      - keycloak-service
